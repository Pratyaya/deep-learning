{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Taken from kaggle kernel: https://www.kaggle.com/laowingkin/netflix-movie-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (24058263, 3)\n",
      "-Dataset examples-\n",
      "          cust_Id  rating        date\n",
      "0              1:     NaN         NaN\n",
      "5000000   2560324     4.0  2005-12-06\n",
      "10000000  2271935     2.0  2005-04-11\n",
      "15000000  1921803     2.0  2005-01-31\n",
      "20000000  1933327     3.0  2004-11-10\n"
     ]
    }
   ],
   "source": [
    "# Skip date\n",
    "df1 = pd.read_csv('/home/ubuntu/netflix_cf/data/combined_data_1.txt', header = None, \n",
    "                  names = ['cust_Id', 'rating','date'], usecols = [0,1,2])\n",
    "\n",
    "df1['rating'] = df1['rating'].astype(float)\n",
    "\n",
    "print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df1.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 shape: (26982302, 3)\n",
      "Dataset 3 shape: (22605786, 3)\n",
      "Dataset 4 shape: (26851926, 3)\n"
     ]
    }
   ],
   "source": [
    "# df2 = pd.read_csv('/home/ubuntu/netflix_cf/data/combined_data_2.txt', header = None, \n",
    "#                   names = ['cust_Id', 'rating', 'date'], usecols = [0,1,2])\n",
    "# df3 = pd.read_csv('/home/ubuntu/netflix_cf/data/combined_data_3.txt', header = None, \n",
    "#                   names = ['cust_Id', 'rating','date'], usecols = [0,1,2])\n",
    "# df4 = pd.read_csv('/home/ubuntu/netflix_cf/data/combined_data_4.txt', header = None,\n",
    "#                   names = ['cust_Id', 'rating','date'], usecols = [0,1,2])\n",
    "\n",
    "\n",
    "# df2['rating'] = df2['rating'].astype(float)\n",
    "# df3['rating'] = df3['rating'].astype(float)\n",
    "# df4['rating'] = df4['rating'].astype(float)\n",
    "\n",
    "# print('Dataset 2 shape: {}'.format(df2.shape))\n",
    "# print('Dataset 3 shape: {}'.format(df3.shape))\n",
    "# print('Dataset 4 shape: {}'.format(df4.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (24058263, 3)\n",
      "-Dataset examples-\n",
      "          cust_Id  rating        date\n",
      "0              1:     NaN         NaN\n",
      "5000000   2560324     4.0  2005-12-06\n",
      "10000000  2271935     2.0  2005-04-11\n",
      "15000000  1921803     2.0  2005-01-31\n",
      "20000000  1933327     3.0  2004-11-10\n"
     ]
    }
   ],
   "source": [
    "# load less data for speed\n",
    "\n",
    "df = df1\n",
    "# df = df1.append(df2)\n",
    "# df = df.append(df3)\n",
    "# df = df.append(df4)\n",
    "\n",
    "df.index = np.arange(0,len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Movie Id column to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = pd.DataFrame(pd.isnull(df.rating))\n",
    "df_nan = df_nan[df_nan['rating'] == True]\n",
    "df_nan = df_nan.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4499, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan[::1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie numpy: [1.000e+00 1.000e+00 1.000e+00 ... 4.499e+03 4.499e+03 4.499e+03]\n",
      "Length: 24053764\n"
     ]
    }
   ],
   "source": [
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "print('Movie numpy: {}'.format(movie_np))\n",
    "print('Length: {}'.format(len(movie_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24053764, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding movie id to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Dataset examples-\n",
      "          cust_Id  rating        date  movie_Id\n",
      "1         1488844     3.0  2005-09-06         1\n",
      "5000996    501954     2.0  2004-08-26       996\n",
      "10001962   404654     5.0  2005-08-29      1962\n",
      "15002876   886608     2.0  2005-09-19      2876\n",
      "20003825  1193835     2.0  2003-08-13      3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# remove those Movie ID rows\n",
    "df = df[pd.notnull(df['rating'])]\n",
    "\n",
    "df['movie_Id'] = movie_np.astype(int)\n",
    "df['cust_Id'] = df['cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this dataframe\n",
    "\n",
    "df.to_pickle('/home/ubuntu/netflix_cf/data/intermediate_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/ubuntu/netflix_cf/data/intermediate_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding date time related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']= df.date.dt.year\n",
    "df['dow']= df.date.dt.dayofweek\n",
    "df['month']= df.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='date',ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>1798</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>2866</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_Id  rating       date  movie_Id  year  dow  month\n",
       "0   510180     5.0 1999-11-11      1798  1999    3     11\n",
       "1   510180     3.0 1999-11-11      2866  1999    3     11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding data\n",
    "We enconde the data to have contiguous ids for users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a handy function modified from fast.ai\n",
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"cust_Id\", \"movie_Id\", \"year\", 'dow', 'month']:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e = encode_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_Id  rating       date  movie_Id  year  dow  month\n",
       "0        0     5.0 1999-11-11         0     0    0      0\n",
       "1        0     3.0 1999-11-11         1     0    0      0\n",
       "2        0     4.0 1999-11-11         2     0    0      0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24053764, 7), (24053764, 7))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by date to split 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation before encoding\n",
    "trn_len = df_e.shape[0]- int(0.2*df_e.shape[0])\n",
    "val_len = int(0.2*df_e.shape[0])\n",
    "\n",
    "train = df_e[:trn_len].copy()\n",
    "val = df_e[trn_len:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]+ val.shape[0] == df_e.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving pickles\n",
    "\n",
    "train.to_pickle('/home/ubuntu/netflix_cf/data/df_train.pkl')\n",
    "val.to_pickle('/home/ubuntu/netflix_cf/data/df_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('/home/ubuntu/netflix_cf/data/df_train.pkl')\n",
    "df_val = pd.read_pickle('/home/ubuntu/netflix_cf/data/df_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_Id  rating       date  movie_Id  year  dow  month\n",
       "0        0     5.0 1999-11-11         0     0    0      0\n",
       "1        0     3.0 1999-11-11         1     0    0      0\n",
       "2        0     4.0 1999-11-11         2     0    0      0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to first try these neural net layers on a small sample dataset to see how it looks like before running on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini = df_train.copy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-12-06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-12-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-12-06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-12-08</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-12-08</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_Id  rating       date  movie_Id\n",
       "0        0     5.0 1999-11-11         0\n",
       "1        0     3.0 1999-11-11         1\n",
       "2        0     4.0 1999-11-11         2\n",
       "3        0     2.0 1999-11-11         3\n",
       "4        0     5.0 1999-11-11         4\n",
       "5        0     3.0 1999-12-06         5\n",
       "6        0     3.0 1999-12-06         6\n",
       "7        0     3.0 1999-12-06         7\n",
       "8        1     3.0 1999-12-08         8\n",
       "9        1     3.0 1999-12-08         9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_items, emb_size = 2, 10, 10\n",
    "\n",
    "\n",
    "user_emb = nn.Embedding(num_users, emb_size)\n",
    "item_emb = nn.Embedding(num_items, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = Variable(torch.LongTensor(df_mini.cust_Id.values))\n",
    "items = Variable(torch.LongTensor(df_mini.movie_Id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.LongTensor of size 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index in embedding layer\n",
    "U = user_emb(users)\n",
    "V = item_emb(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 10]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0729\n",
       "-1.0216\n",
       " 1.7603\n",
       "-3.0100\n",
       " 0.7900\n",
       "-0.7482\n",
       " 1.4096\n",
       " 2.6721\n",
       " 0.4361\n",
       "-2.0313\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U*V).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset class and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, movies, users, ratings):\n",
    "        'Initialization'\n",
    "        self.movies = movies\n",
    "        self.users = users\n",
    "        self.ratings = ratings\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        U = self.movies[index]\n",
    "        V = self.users[index]\n",
    "        y = self.ratings[index]\n",
    "\n",
    "        return [U, V, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = torch.LongTensor(df_train.cust_Id.values)\n",
    "movies = torch.LongTensor(df_train.movie_Id.values)\n",
    "ratings = torch.FloatTensor(df_train.rating.values)\n",
    "\n",
    "train_dataset = Dataset(users, movies, ratings)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2], \n",
       "  0\n",
       "  1\n",
       " [torch.LongTensor of size 2], \n",
       "  5\n",
       "  3\n",
       " [torch.FloatTensor of size 2]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1.1441e+05\n",
       "  1.7940e+05\n",
       "  2.4209e+05\n",
       "      ⋮     \n",
       "  1.1411e+05\n",
       "  1.9630e+05\n",
       "  1.6677e+05\n",
       " [torch.LongTensor of size 100000], \n",
       "  1146\n",
       "  1426\n",
       "  2645\n",
       "   ⋮  \n",
       "  1610\n",
       "    27\n",
       "  1570\n",
       " [torch.LongTensor of size 100000], \n",
       "  3\n",
       "  3\n",
       "  3\n",
       " ⋮ \n",
       "  5\n",
       "  3\n",
       "  3\n",
       " [torch.DoubleTensor of size 100000]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataloader\n",
    "\n",
    "users_val = torch.LongTensor(df_val.cust_Id.values)\n",
    "movies_val = torch.LongTensor(df_val.movie_Id.values)\n",
    "ratings_val = torch.FloatTensor(df_val.rating.values)\n",
    "\n",
    "val_dataset = Dataset(users_val, movies_val, ratings_val)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7f1125899f98>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training MF model with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return (U*V).sum(1) +  b_u  + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteration per epoch\n",
    "20000000/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    U,V,y = data\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  4.1952e+04\n",
       "  1.2634e+05\n",
       "  1.0288e+05\n",
       "      ⋮     \n",
       "  2.5643e+04\n",
       "  1.3268e+05\n",
       "  2.6544e+05\n",
       " [torch.LongTensor of size 100000], \n",
       "   703\n",
       "  2535\n",
       "  2884\n",
       "   ⋮  \n",
       "  3016\n",
       "   744\n",
       "  3144\n",
       " [torch.LongTensor of size 100000], \n",
       "  2\n",
       "  4\n",
       "  2\n",
       " ⋮ \n",
       "  4\n",
       "  4\n",
       "  5\n",
       " [torch.DoubleTensor of size 100000])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U,V,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389223 4403\n"
     ]
    }
   ],
   "source": [
    "# instantiating model class\n",
    "num_users = len(df_train.cust_Id.unique())\n",
    "num_items = len(df_train.movie_Id.unique())\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF_bias(num_users, num_items, emb_size=100).cuda()  # if you have a GPU .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  1.3964  0.2576  0.8163  ...   0.9777  1.1301  4.6421\n",
       "  2.2505  1.5438  4.5505  ...   1.1837  1.6772  4.9862\n",
       "  2.5746  1.3042  0.8057  ...   2.3677  3.7980  2.8203\n",
       "           ...             ⋱             ...          \n",
       "  2.5007  3.4935  0.8847  ...   4.0331  3.1606  4.1015\n",
       "  4.0530  1.7925  2.6780  ...   4.3488  3.7237  0.2395\n",
       "  1.9705  0.3177  1.9255  ...   0.4876  4.2783  4.8671\n",
       " [torch.FloatTensor of size 389223x100], Parameter containing:\n",
       "  6.3819e-03\n",
       "  6.9740e-03\n",
       " -7.4664e-03\n",
       "      ⋮      \n",
       "  1.6735e-03\n",
       " -7.1889e-03\n",
       " -2.5451e-03\n",
       " [torch.FloatTensor of size 389223x1], Parameter containing:\n",
       "  1.7135e-02  8.7493e-03  1.0590e-02  ...   3.1343e-03  2.2114e-02  2.2622e-02\n",
       "  3.2340e-02  3.3855e-02  4.0062e-03  ...   2.4309e-02  8.8655e-03  4.0964e-02\n",
       "  1.5294e-02  2.6389e-02  4.6789e-02  ...   6.6698e-03  3.5113e-02  5.1873e-03\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.3312e-02  4.7135e-02  9.1409e-03  ...   9.6253e-03  6.6988e-03  3.7533e-02\n",
       "  4.9065e-02  3.0494e-02  9.9508e-03  ...   2.7449e-02  4.5293e-02  1.9963e-02\n",
       "  8.4349e-03  4.0743e-02  2.8020e-02  ...   2.1964e-02  4.7688e-02  2.4798e-02\n",
       " [torch.FloatTensor of size 4403x100], Parameter containing:\n",
       " 1.00000e-03 *\n",
       "  9.8018\n",
       "  0.6553\n",
       "  0.5135\n",
       "    ⋮    \n",
       " -5.6697\n",
       "  2.3919\n",
       " -8.1003\n",
       " [torch.FloatTensor of size 4403x1]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 389223*100, 4403*100 and 1*() bias learnable params\n",
    "\n",
    "[p for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    model.train() # into training mode\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for j, data in enumerate(train_loader):\n",
    "            users, items, ratings = data\n",
    "            users = Variable(users)\n",
    "            items = Variable(items)\n",
    "            ratings = Variable(ratings).float()\n",
    "            \n",
    "            users = users.cuda() # put on gpu\n",
    "            items = items.cuda()\n",
    "            ratings = ratings.cuda()            \n",
    "            if unsqueeze:\n",
    "                ratings = ratings.unsqueeze(1)\n",
    "            y_hat = model(users, items)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "        print(\"training loss for epoch \",i+1, \": \", running_loss/j+1) # used to be loss.data[0]\n",
    "    test_loss(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19243012])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([19243012, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what unsqueeze does\n",
    "\n",
    "ratings = torch.FloatTensor(df_train.rating.values)\n",
    "print(ratings.shape)\n",
    "ratings = ratings.unsqueeze(1)  #.cuda()\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 193)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader), len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining test loss which has been used in train_epochs\n",
    "\n",
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval() # go to evaluation mode\n",
    "    \n",
    "    running_loss = 0.\n",
    "    for j, data in enumerate(val_loader):\n",
    "        users, items, ratings = data\n",
    "        users, items, ratings = Variable(users), Variable(items), Variable(ratings).float()\n",
    "        \n",
    "        users = users.cuda() # put on gpu\n",
    "        items = items.cuda()\n",
    "        ratings = ratings.cuda()       \n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss_now = F.mse_loss(y_hat, ratings)\n",
    "        running_loss+= loss_now.data[0]\n",
    "    print(\"validation loss\", \": \", running_loss/len(val_loader)) # j means this many iterations till end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8164567404116192\n",
      "training loss for epoch  2 :  1.7305999736612043\n",
      "training loss for epoch  3 :  1.681645206796626\n",
      "training loss for epoch  4 :  1.6428651694829264\n",
      "training loss for epoch  5 :  1.609310308160881\n",
      "training loss for epoch  6 :  1.5779485749080777\n",
      "training loss for epoch  7 :  1.5482694699118533\n",
      "training loss for epoch  8 :  1.519811940845102\n",
      "training loss for epoch  9 :  1.4926153641814988\n",
      "training loss for epoch  10 :  1.4670419896331925\n",
      "validation loss :  3.554822330121641\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is high, but training loss is low. How to debug this? Let's see distribution of training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1121b395f8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.rating.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f11219f7710>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_val.rating.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and train distributions are same. Difference in training and validation losses might not be due to covariance shift then. Let's try `weidht_decay` to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.3959827586077154\n",
      "training loss for epoch  2 :  1.3933158125728369\n",
      "training loss for epoch  3 :  1.4095620855999489\n",
      "training loss for epoch  4 :  1.430343547835946\n",
      "training loss for epoch  5 :  1.452937744402637\n",
      "validation loss :  1.7792416590231437\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=5, lr=0.001, wd=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `weight decay` helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.4596793348900974\n",
      "training loss for epoch  2 :  1.4576306299616892\n",
      "training loss for epoch  3 :  1.4560284797723095\n",
      "training loss for epoch  4 :  1.454666225084414\n",
      "training loss for epoch  5 :  1.453537404537201\n",
      "validation loss :  1.709446355148598\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=5, lr=0.0001, wd=1e-6) # lower learning rate # lower regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train even further to decrease validation and train loss, but I would carry on with neural net version as it might perform better than MF version. Also, it takes time to train each epoch even on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without date related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
    "# Here we could get better results by keep playing with regularization.\n",
    "    \n",
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(CollabFNet, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.drop2 = nn.Dropout(0.1) # changed from 0. actually can do only with dropout 1\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = torch.cat([U, V], dim=1)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = CollabFNet(num_users, num_items, emb_size=100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.9723842836295566\n",
      "training loss for epoch  2 :  1.896787578550478\n",
      "training loss for epoch  3 :  1.8759232955053449\n",
      "training loss for epoch  4 :  1.8693881261472902\n",
      "training loss for epoch  5 :  1.8592914401864014\n",
      "validation loss :  0.9192858669492934\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model_nn, epochs=5, lr=0.01, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not overfitting yet. Let's try 3 more epochs with same lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8429234139621258\n",
      "training loss for epoch  2 :  1.8270095620925226\n",
      "training loss for epoch  3 :  1.8185425773262978\n",
      "validation loss :  0.9005276008888528\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model_nn, epochs=3, lr=0.01, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8143312806884446\n",
      "training loss for epoch  2 :  1.8084728177636862\n",
      "training loss for epoch  3 :  1.804810949911674\n",
      "validation loss :  0.9094064809657909\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model_nn, epochs=3, lr=0.01, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(Variable(torch.LongTensor(df_val.cust_Id.values)).cuda(),\n",
    "              Variable(torch.LongTensor(df_val.movie_Id.values)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-66.29216, 77.088524)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.data.cpu().numpy().min(), y_hat.data.cpu().numpy().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings that are being predicted are way off than the range of 0 to 5. Adding last sigmoid layer to predict ratings between 0 and 5 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-11-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_Id  rating       date  movie_Id  year  dow  month\n",
       "0        0     5.0 1999-11-11         0     0    0      0\n",
       "1        0     3.0 1999-11-11         1     0    0      0\n",
       "2        0     4.0 1999-11-11         2     0    0      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_Id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_Id</th>\n",
       "      <th>year</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19243012</th>\n",
       "      <td>388544</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-08-01</td>\n",
       "      <td>2604</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19243013</th>\n",
       "      <td>258382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-08-01</td>\n",
       "      <td>1930</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19243014</th>\n",
       "      <td>141157</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-08-01</td>\n",
       "      <td>1930</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_Id  rating       date  movie_Id  year  dow  month\n",
       "19243012   388544     3.0 2005-08-01      2604     6    1      9\n",
       "19243013   258382     3.0 2005-08-01      1930     6    1      9\n",
       "19243014   141157     4.0 2005-08-01      1930     6    1      9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yr_mean = df_train.year.mean()\n",
    "# dow_mean = df_train.dow.mean()\n",
    "# mnth_mean = df_train.month.mean()\n",
    "\n",
    "# yr_std = df_train.year.std()\n",
    "# dow_std = df_train.dow.std()\n",
    "# mnth_std = df_train.month.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['year'] = (df_train.year - yr_mean)/ yr_std\n",
    "# df_train['dow'] = (df_train.dow - dow_mean)/ dow_std\n",
    "# df_train['month'] = (df_train.month - mnth_mean)/ mnth_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val['year'] = (df_val.year - yr_mean)/ yr_std\n",
    "# df_val['dow'] = (df_val.dow - dow_mean)/ dow_std\n",
    "# df_val['month'] = (df_val.month - mnth_mean)/ mnth_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset2(data.Dataset):\n",
    "    \n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, df):\n",
    "        'Initialization'\n",
    "        self.movies = torch.LongTensor(df.movie_Id.values)\n",
    "        self.users = torch.LongTensor(df.cust_Id.values)\n",
    "        self.ratings = torch.FloatTensor(df.rating.values)\n",
    "        self.year = torch.LongTensor(df.year.values)\n",
    "        self.month = torch.LongTensor(df.month.values)\n",
    "        self.dow = torch.LongTensor(df.dow.values)        \n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        Mov = self.movies[index]\n",
    "        Usr = self.users[index]\n",
    "        Yr = self.year[index]\n",
    "        Mon = self.month[index]\n",
    "        Dow = self.dow[index]\n",
    "        \n",
    "        R = self.ratings[index]\n",
    "\n",
    "        return [Mov, Usr, Yr, Mon, Dow, R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset2 = Dataset2(df_train)\n",
    "train_loader2 = torch.utils.data.DataLoader(train_dataset2, batch_size=50000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataloader\n",
    "\n",
    "val_dataset2 = Dataset2(df_val)\n",
    "val_loader2 = torch.utils.data.DataLoader(val_dataset2, batch_size=50000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0\n",
       "  1\n",
       " [torch.LongTensor of size 2], \n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2], \n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2], \n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2], \n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2], \n",
       "  5\n",
       "  3\n",
       " [torch.FloatTensor of size 2]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result := ((Input - InputLow) / (InputHigh - InputLow)) * (OutputHigh - OutputLow) + OutputLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here there is no matrix multiplication, we could potentially make the embeddings of different sizes.\n",
    "# Here we could get better results by keep playing with regularization.\n",
    "    \n",
    "class CollabFNet2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_items,\n",
    "                 num_users, \n",
    "                 num_yrs, \n",
    "                 num_months,\n",
    "                 num_dow, \n",
    "                 emb_size=100, \n",
    "                 emb_size2 = 5, n_hidden=20):\n",
    "        \n",
    "        super(CollabFNet2, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.yr_emb = nn.Embedding(num_yrs, emb_size2)\n",
    "        self.dow_emb = nn.Embedding(num_dow, emb_size2)\n",
    "        self.month_emb = nn.Embedding(num_months, emb_size2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(emb_size*2 + emb_size2*3, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.drop2 = nn.Dropout(0.1)  # changed from 0. actually can do only with dropout 1\n",
    "        \n",
    "    def forward(self, Mov, Usr, Yr, Mon, Dow):\n",
    "    \n",
    "        Usr = self.user_emb(Usr)\n",
    "        Mov = self.item_emb(Mov)\n",
    "        Yr = self.yr_emb(Yr)\n",
    "        Dow = self.dow_emb(Dow)\n",
    "        Mon = self.month_emb(Mon)        \n",
    "        \n",
    "        x = torch.cat([Mov,Usr, Yr, Mon, Dow],dim=1)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.lin2(x)\n",
    "        return F.sigmoid(x)*4 + 1 # to make it b/w 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs2(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        model.train() # into training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for j, (items, users, yr, month, dow, ratings) in enumerate(train_loader2):\n",
    "            users = Variable(users).cuda()\n",
    "            items = Variable(items).cuda()\n",
    "            ratings = Variable(ratings).float().cuda()\n",
    "            yr = Variable(yr).cuda()\n",
    "            month = Variable(month).cuda()\n",
    "            dow = Variable(dow).cuda()            \n",
    "            \n",
    "            if unsqueeze:\n",
    "                ratings = ratings.unsqueeze(1)\n",
    "            y_hat = model(items, users, yr, month, dow)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "        print(\"training loss for epoch \",i+1, \": \", running_loss/j+1) # used to be loss.data[0]\n",
    "        test_loss2(model, unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining test loss which has been used in train_epochs\n",
    "\n",
    "def test_loss2(model, unsqueeze=False):\n",
    "    model.eval() # go to evaluation mode\n",
    "    \n",
    "    running_loss = 0.\n",
    "    for j, (items, users, yr, month, dow, ratings) in enumerate(val_loader2):\n",
    "        users = Variable(users).cuda()\n",
    "        items = Variable(items).cuda()\n",
    "        ratings = Variable(ratings).float().cuda()\n",
    "        yr = Variable(yr).cuda()\n",
    "        month = Variable(month).cuda()\n",
    "        dow = Variable(dow).cuda()\n",
    "        \n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(items, users, yr, month, dow)\n",
    "        loss_now = F.mse_loss(y_hat, ratings)\n",
    "        running_loss+= loss_now.data[0]\n",
    "    print(\"validation loss\", \": \", running_loss/len(val_loader2)) # j means this many iterations till end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470758 4499 7 7 12\n"
     ]
    }
   ],
   "source": [
    "# instantiating model class\n",
    "num_users = len(df.cust_Id.unique())\n",
    "num_items = len(df.movie_Id.unique())\n",
    "num_yrs = len(df.year.unique())\n",
    "num_dow =  len(df.dow.unique())\n",
    "num_months = len(df.month.unique()) \n",
    "\n",
    "print(num_users, num_items, num_yrs, num_dow, num_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn2 = CollabFNet2(num_items,\n",
    "                 num_users, \n",
    "                 num_yrs, \n",
    "                 num_months,\n",
    "                 num_dow, \n",
    "                        emb_size=50, emb_size2=5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollabFNet2(\n",
       "  (user_emb): Embedding(470758, 50)\n",
       "  (item_emb): Embedding(4499, 50)\n",
       "  (yr_emb): Embedding(7, 5)\n",
       "  (dow_emb): Embedding(7, 5)\n",
       "  (month_emb): Embedding(12, 5)\n",
       "  (lin1): Linear(in_features=115, out_features=20, bias=True)\n",
       "  (lin2): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.960017153682808\n",
      "validation loss :  1.0423250905017263\n",
      "training loss for epoch  2 :  1.884606457160165\n",
      "validation loss :  1.0395030729549448\n",
      "training loss for epoch  3 :  1.8819063971750438\n",
      "validation loss :  1.0340662076301181\n",
      "training loss for epoch  4 :  1.8879277695280812\n",
      "validation loss :  1.035488827326863\n",
      "training loss for epoch  5 :  1.8914600601419806\n",
      "validation loss :  1.0323809864594764\n"
     ]
    }
   ],
   "source": [
    "train_epocs2(model_nn2, epochs=5, lr=0.01, wd=1e-5,unsqueeze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is increasing after some epochs. Lets try to find right learning rate using lr finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrfinder(start, end, model, train_loader2):\n",
    "    model.train() # into training mode\n",
    "    lrs = np.linspace(start, end, len(train_loader2))\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(parameters, start)\n",
    "    losses = []\n",
    "    \n",
    "    for j, (items, users, yr, month, dow, ratings) in enumerate(train_loader2):\n",
    "        optimizer.param_groups[0]['lr'] =lrs[j]\n",
    "\n",
    "        users = Variable(users).cuda()\n",
    "        items = Variable(items).cuda()\n",
    "        ratings = Variable(ratings).float().cuda()\n",
    "        yr = Variable(yr).cuda()\n",
    "        month = Variable(month).cuda()\n",
    "        dow = Variable(dow).cuda()            \n",
    "        y_hat = model(items, users, yr, month, dow)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data[0])\n",
    "    plt.plot(lrs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn_copy = CollabFNet2(num_items,\n",
    "                 num_users, \n",
    "                 num_yrs, \n",
    "                 num_months,\n",
    "                 num_dow, \n",
    "                        emb_size=100, emb_size2=5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXd4m+XV/z+3hveI45G9nDgJCZAEQiAtIyGMlFJGSxlltIW+gbZQ+raFlvbXUroLb0tLoczSAC2kQFugZY+QQCbZe+9lO3YSb8uW7t8fzyPp0bAlWbIl2edzXbksPfNElr86+t7nPrfSWiMIgiD0LmzJDkAQBEFIPCLugiAIvRARd0EQhF6IiLsgCEIvRMRdEAShFyLiLgiC0AsRcRcEQeiFiLgLgiD0QkTcBUEQeiGOZN24pKREjxw5Mlm3FwRBSEtWrlx5VGtdGum4pIn7yJEjWbFiRbJuLwiCkJYopfZGc5zYMoIgCL0QEXdBEIReiIi7IAhCL0TEXRAEoRci4i4IgtALEXEXBEHohYi4C4Ig9EJE3AVBiAmPR/PiJ/tpd3uSHYrQCSLugiDExIsr9nP3P9fxl493JzsUoRNE3AVBiInjzW0A1Da6khyJ0Bki7oIgxIQyf+qkRiFEQsRdEISYUKa6ezwi76lMRHFXSj2tlKpSSm3oYP8MpdQJpdQa899PEh+mIAipgjJzd5H21CaarpBzgYeBZzs55iOt9aUJiUgQhJTGm7kLqU3EzF1rvRCo7YFYBEFII7Sk7ilNojz36UqptUqpN5VSExN0TUEQUhBlpu4eUfeUJhGLdawCRmitG5RSlwCvABXhDlRKzQHmAAwfPjwBtxYEoacRVyY9iDtz11rXaa0bzMdvAE6lVEkHxz6htZ6qtZ5aWhpxlShBEFIQr+euJXNPaeIWd6XUQGV+T1NKTTOvWRPvdQVBSE2kzj09iGjLKKVeAGYAJUqpA8C9gBNAa/0YcBXwdaVUO9AMXKvlI10Qei1ez13+ylObiOKutb4uwv6HMUolBUHoA/hsGcndUxqZoSoIQkz4bBnR9pRGxF0QhNiQWUxpgYi7IAgxIQOq6YGIuyAIMSGlkOmBiLsgCDHhaxwm2p7SiLgLghAT/sw9uXEInSPiLghCTPg9d1H3VEbEXRCEmJDMPT0QcRcEISZksY70QMRdEITYkMw9LRBxFwQhJmze3jKSu6c0Iu6CIMSEb36qaHtKI+IuCEKXEG1PbUTcBUGICZmhmh6IuAuC0CVE2lMbEXdB6EM0trZzoqktrmt4E3ZJ3FMbEXdB6EOce/98Jv3snbiu4TFVXbQ9tRFxF4Q+RE2jK+5reEVdPPfURsRdEITY0AE/hBRFxF0QhJjQou5pgYi7IAgx4RtQFXVPadJO3OdvreKC3y/gwLGmZIciCH0Sj1TLpAURxV0p9bRSqkoptSHCcWcopdqVUlclLrzw7KhqoLKutbtvIwhCGLwZu4h7ahNN5j4XmN3ZAUopO/BbIL4aqygozcsEoLpexF0QkoHYMulBRHHXWi8EaiMcdgfwT6AqEUF1Rmm+Ie5HG0TcBSEZ+EshkxqGEIG4PXel1BDgSuDR+MOJTP/cDEDEXRCShZZJTGlBIgZU/wB8X2vtiXSgUmqOUmqFUmpFdXV1l27mtNvon5shtowgJAlr+wGZyJS6JELcpwLzlFJ7gKuAPyulrgh3oNb6Ca31VK311NLS0i7fsCQvQzJ3QUgSXkF/b3Mlo+55I8nRCB3hiPcCWutR3sdKqbnAf7XWr8R73c4ozc/kaEP806gFQYgdydXTg4jirpR6AZgBlCilDgD3Ak4ArfVj3RpdB5TkZbJ63/Fk3FoQ+jzixKQHEcVda31dtBfTWn8lrmiipCQvU2wZQUgSHlH3tCDtZqiCUTHT5HLT0uZOdiiC0Odxe0TsU5G0FPdisxyyNgHtSwVBiI3gxF2SrNQkLcW9SMRdEJJG8MzUZhH3lCQtxV0yd0FIHsEuTLNLxD0VSUtx92bux5pE3AWhpxFbJj1IS3H3Zu41UusuCD2O2DLpQVqKe0GWE5uSzF0QkkFw5i62TGqSluJusymKcjISstivIAjxIZl7apKW4g5GrfsxEXdB6HE8QSOq4rmnJmkr7kU5GVItIwhdJJ5ujsFnSuaemqStuOdnOWhobU92GIKQlsTTQSDUc4/Y7VtIAmkr7rmZDhpF3AWhS8TTH0aqZdKDtBX3PMncBaHLxNMOJvhc8dxTk/QV90wRd0HoKnEtbh2U9UspZGqS1uLe0uah3S1+nyDESlyee9BzsWVSk7QV99xMoxV9Y6u8sQQhVuLy3IMHVEXcU5K0Ffe8TDsADS6xZgQhVuLx3EMGVMWWSUnSWNydADS0iLgLQqzEk7kHfzC4xBpNSdJW3HO9mbsMqgpCzCSyzl3GvVKTtBX3/Cyv5y7iLgixEt8M1cBz292yzF4qkrbi7h1QlcxdEGInrmVPg85tkzVUU5L0FfcMEXdB6Crxee7BmbvYMqlI2oq715aRAVVBiJ1ElkKKLZOaRBR3pdTTSqkqpdSGDvZfrpRap5Rao5RaoZQ6O/FhhuKvcxdxF4RYSeQkpjaPZO6pSDSZ+1xgdif73wcmaa0nAzcDTyUgrog47TYyHTaxZQShCyS2WkYy91QkorhrrRcCtZ3sb9D+ofdcQj/Yu42CbCd1YssIQlRYK2QS2RWyXQZUU5KEeO5KqSuVUluA1zGy946Om2NaNyuqq6vjvm9BloO6lra4ryMIfQGrnifWcxdbJhVJiLhrrf+ttR4PXAH8vJPjntBaT9VaTy0tLY37vgXZTuqaRdwFIRqsgh6fLSOZezqQ0GoZ08IpV0qVJPK6HVGQJeIuCNHiSVTmbnlstynaJHNPSeIWd6XUGKWUMh+fBmQCNfFeNxrEcxeE6Elc5u5/nOWwyYBqiuKIdIBS6gVgBlCilDoA3As4AbTWjwFfAG5SSrUBzcA1Op65zTFQkOWQzF0QosTTDQOqWU477VIKmZJEFHet9XUR9v8W+G3CIooBI3NvQ2uN+eVBEIQOCLRlEnOdLKddypFTlLSdoQqG597m1rS0SeYgCJEItGUSUy2T6bRJtUyKktbiXpht9HQ/IdaMIEREWzQ4vgIX/8mZDrs0DktR0lrcC7INV0lq3QUhMgnz3ANsGRtuEfeUJL3FPcvI3GVQVRAik6hqGet1shx23B4dl80jdA/pLe6mLSOZuyBEJmF17kGZO0CblEOmHGkt7v1Mca9tFHEXhEjoRNW5Wx5nOY3lLqUcMvVIa3EvK8gEoKq+JcmRCELq0z2ZuyHukrmnHmkt7jkZDvKzHFTVtSY7FEFIedzdMonJkBAph0w90lrcAQYUZFFZJ5m7IETCY0nd41pC1Vrn7vDaMpK5pxppL+5l+Zki7oIQBVZRjm8Sk//cDId3QFUy91Qj7cXdyNzFlhGESATWuXf9OtZTM+xeW0Yy91Qj7cW9rCCT6vpWqbMVhAgEiHsc6m79U3N6xV2qZVKOtBf3AflZuNwejjdJOaQgdEbiGof5T3Y6jIZ94rmnHmkv7sV5GQDUNIo1IwidEVDnHseQame2zJYjdVKanCKkvbhL8zBBiA5PwIBqHBcKqJYJHFCd/YePmPHAh3FcXEgUIu6C0EdI9GIdF04YwLD+OUCgLdPkcnf52kLiEHEXhD6CtXtjXNUyGsYOyOPJm6b66tylFDL16DXiXtcsq8EIQmfogAHVrqu7R2sUxkCq024OqEopZMqR9uJeIJm7IERFIldi8q5q6ZBSyJQl7cXdabeRk2EXcReECCSqn7sG35rFDpvxs82t46qdFxJP2os7GNaMiLsgdE6i6ty1Bu9y9A6LLdMm2XtKIeIuCH0EHUO1zCurDzLyB69z+ERz2Ov4bBmb35YR3z21iCjuSqmnlVJVSqkNHey/Xim1Tim1Xim1WCk1KfFhdk5BtlOW2hOECATWuXcuxC+vPADA9sqGkH2GLWM8tg6oSsVMahFN5j4XmN3J/t3AeVrrU4CfA08kIK6YkMxdECITS+Mwr3iHQ1uqZawDqq5uFnfpHxUbEcVda70QqO1k/2Kt9THz6VJgaIJii5pCM3NvaXPz+3e2itALQhi6MqAa7jAN2LyZu2VA1WrLvLn+cFgxfnXNQXYfbYw2ZB83/mUZZ/zy/ZjP68sk2nO/BXizo51KqTlKqRVKqRXV1dUJu+moklwO17Xw6zc289AHO3huyZ6EXVsQegvW8c5Inru3Gibccdriy/gyd7cnwJb5+t9X8e6myqDzNHfOW8OlD30Uc+wfbT/K0Qbp/hoLCRN3pdRMDHH/fkfHaK2f0FpP1VpPLS0tTdStufTUQWgNzyzZC8Ca/cdZuquGzYfraGmTqdCCAIlrP2BMYjLweu4utydkHdWjDa6A563thvg3xtGeoKpeGgRGS0LEXSl1KvAUcLnWuiYR14yFEcW5TC8v9j1/b3MV1z6xlM/88SOeXbKnp8MRhJQkFlvGZ7l3cJzXk882F8huafOEDKgGd55saI1/FvnOqtABXiE8cYu7Umo48C/gRq31tvhD6hrP3jKNFf/vAs6pKAnY3hV/TxB6I7G0H/CKd7jWwFqDzWLLZNhtNLe5Q8U96NSGlq6Lu3ey1I5qEfdoiaYU8gVgCTBOKXVAKXWLUuo2pdRt5iE/AYqBPyul1iilVnRjvB3itNsoycvk5rNHkZ/pYPmPZjF+YH7IV0NB6KvEVC1j/gz3GaDx2zIAWU4bzS53iC0T7I/Hk7nnZTkAeG7JXukXHyWOSAdora+LsP9rwNcSFlGczBxXxvr7LgagrCCLKlk8WxCA2OrcVSe1kB5PYKlkdobdFPfAzN0VJPaNcYh7k8tNeWku26saeGX1QeacO7rL1+or9IoZqh0xID9TFs8WBGB7ZT3NluKCqEshO8zc/eqe7bSHtWWaXYFi3ujqmri3uz242j1cMXkIRTlOdh9t6tJ1+hq9W9wLsqhuaA3oYy0IfY36ljYufHAh331xjW9bRM/d/OnusBTS/zw7w0Fzmzuk/UDwoh31XfTcm8wPpZwMO6NKctl9NDV894bWdhbtOBrVsVuP1HPN40uoa+m5OTi9XNwzcXu0rK8q9Gla2oyM2uqJRztDNVy/GOskJoBs03MPnqEaLO6Nre6Aa0dLU6tX3B2MKsnr0SKJFz/Zz9f/tjLsvpvnfsL1Ty3r1Pp9ZP4OfvvWFt5Yf5hlu2tZsaeWE009I/C9XNyzAKgSa0bow4QT08h17mbPmHCdHjWBtkxGeFsm2GP3PrcFBVTb6OLllQdYd+A4+2pCLRevnZObaae8NJfKuta4/HsIHHN4Y/1hXlqxP+xxd/9zHW9uOMLO6gb+8ck+332bXW6W7zYm7m88VBdwjtUpeODtrTz64U5fhr9m/wlm/N98fv3m5rjij4ZeLe4jS3IB2HDwRJIjEYTkEd43j45wlqbH0hUSTM/dFWrL7K1tCugqWW8KY/BnzTOL9/C9l9Zy2cOLOPeB+Ty7ZA+udv8HRWDmbvxN76kJn717PDrsB8SPX9nA0x/vBuD3726j4kdv8svXNwHwjb+v4q6X14Wcc/C4P/ZZv1vA9/+5nj+8Z1R7L9vtn86z6XCguF/xyCIuf/hj9tf641ix1+jQ8releznW1MbJgwvDxp9IerW4V5TlMagwiw+3Jq7VgSCkG+EEOnK1jPGzPdy5BFfLOGhpC7Vllu+uZfqvP/A992a97R5Nu9vDK6sPcvvzq1i6K3De409e3cg/Vx3wn+fN3DPsDOmXDcDBY6GtiAEeXbCTcx+Yz46qBrZV1nPJHz9i06E65n2yj3mf7GN/bRN/nr+Ddo/myY928/t3/VNzmi020vEmFzf9ZVmA/QTw7JK97K1pZMuRegD65TjZeOgE85bv4/svr2Pz4TrWHzzB2gMnuHPe6oBz8zMd1DYapdnnViRuhn5HRCyFTGeUUswYV8Z/1h6ize3Bae/Vn2WCEJZw1kq0qyaF9dy1DrBWsp02msKUQgZjtVKa2tw8PH8HO8wZpyOKc3jvO+exaMdR5jy3kn+tOsB104YDftHNzrAzpMgQ90PHw4v7O2Y/m9+/u5XV+45z+EQLP/vvRtrcmm2VDfzi9U3YlOKfX5/OFx5dzEPvb/edu3r/MQqznUwcXMhzS/ays7qRv37lDNrM1gqnjejHRQ8u5K6X1zGwIIvBhVmcNqKI/647zBvrjwDwD9Peyc2ws2rfcQCW/3AW+481YVOKK/+8mHMqSijMcXb6WiWCXi3uAGeO6s8Ly/exq7qRcQPzkx2OIPQ44WzzSNruzVjdYU4OPtVbCtnRYh3G4h7KZ8uAIdiVloHIAQVZOO02Zowr485ZFTzw9lYOHm9mSL9si+fuoDg3g0yHjZ+/vpmnF+3h7IoSdlQ1cOFJA2htd7N2vyGob6w/QpEpoEt3+Zvavr2xki9PH8HpI4rY9LOLmfCTt337vvTkMgAeu+E0nl26l/PGljJzfFnA/+XHl07gbtPCOX98GXdfPJ7lu2sZNzCf6aOLuf+trQDc+7mJ3P3PdVx/5nDKCrIoM8f/NphzcHqCXi/uXkHfcqROxF3ok4TN3COWQnoHVMN57oGTnLI6GFD1UtfcTpvHw+vrDvu21TS4AkojvcUPABdPHMADb2/lg82V3Dh9pMVzt6OUYnC/bHYfbWRfbRPPL9sH4BvcBPj8lCEU52Vwx6wKnluylwfe3srw/jnkZzkozHbyzfPHmNdz8KfrpvDskj18sueY7x7feXEtTS431142LOT/8sXTh7JgazWvrz/M6NJchhfnsOCumTjtCptSbK9sQGvNF6cOZfLwflSU5QWcn5fZc5Lb68W9vDQXu02x1fTIBKGvEc88j7Dn6sD2AzlOB652T4cdWKsbWnhk/s6Abd4B0f65GdQ2uijLz/TtG12ax8jiHN7bXMWN00daPHdDrrwfIp8/bQj/Xn3QN2D8+6snUZDlZMa4Ul8r4lvOHsWpQwuZMKiA4jz/Pbx8btJgPjdpMPe+uoHTRhQxqDCbqx9fQk6GnRnjykKOV0rx0HVTuGjiAM4xffPsDLtv/4PXTPY9Hjsguclkrxf3TIed8pJctlWKuAt9k/DZdyIHVA0h7WiS0t6aJt7eeIRzKkq4/swR3Pa3lb5a9XED8lmyqyZg4FIpxXljS3lxxQH21zbxqzc2m/cxRNTrt39jxhi+PWssRxtbWbv/OJ8/LXSdoCyn3SfCnXHf5Sf7Ht9x/hgy7LYA0bZitykunzwk4jWTTa8Xd4AJgwtYvLPG5/0JQl8ifDlj5+f4JzGF8dw1QQOqhgh2NPvyt29tocnl5pszx2A3VXyvmbmXl+ayZFdNyN/lGaP688ySvfzPsytoc2vunFVBlnmfR284nXnL9zG6NBelFMOLczhteFHn/6EY+O5F4xJ2rWTSJ8pHzq0opbq+lQ0H6yIfLAi9jI5q1aMhfOYe3BXSFPdmf+ZekpfBkzdNBWBbZQOfmzSYM0f1930QeKtkbj9/DFdPHcqt55YH3OOMkf0B2HKknq98aiT/e+FY376LJw7kr1+dJolaBPpE5j5zfBlKwXubKzllaPdPHhCEVCKsQEfQdu8YbNgPhqCukDmmF27N3Evzs7jgJL9n/asrT0YpRXlpLgVZDlbtO06W08bAgizuv2pSyD0GFGRx6tBCWtrcfOeisSH7hcj0icy9f24Gpw0v4v0tlZEPFoReRniB7lzdvQ3DOvLcCWg/YMhIXXMbGeZA5p2zxqCU4n8vGMvcr55BfpZRlpiT4eD6s0YAcOWUIZ1m3y/f9ine/va5FGR1f014b6RPZO4As04q4/63tnLkRAsDC7MinyAIvYSwM1TNn4t2HKWhtZ2LJw4Me054z10HDIB6M/fjzW30y3Gy/EcX+PbdeUFFyPnfvqCCs8qLOWdMScg+KxmOPpF7dht95tW74KQBAJK9C32Ozjz3659axq3PhXY99Il7Bxm+NeH21m4fa3RFNQs802HnvLGl2ILn9gsJpc+Ie0VZHkP6ZbNA+swIfYzwk5g6P8cr7uH70gR2hczP8nru7TjtItipQp8Rd6UU544tYfHOmog9MAShN9GVxmGdZe7BXSGtsy6lf1Pq0Kd+E+dWlNLQ2s66A8eTHYogdJlml5umGJas60oppHdA1d3BYh0B4p7lF3dvWaSQfPqUuE8xJzrM31LNgWOyDqOQnpz+i3cDGl5FwiruNgVOu4pYCuk9py1c47CgyYCZDruvSqYoNyPquITupU+J+4CCTEryMnl4/g7O/u38ZIcjCF0iePm6SFitlQyHDaVUiOcebNN06rkTuuCGN3vv3wOtbIXoiCjuSqmnlVJVSqkNHewfr5RaopRqVUp9L/EhJg6llG/wB+iw0ZEg9CasAp1ht2FToWIevNBGZ567DuoKCf5BVcncU4doMve5wOxO9tcC3wL+LxEBdTdnlRf7HnunQAtCbyZA3B12bEqFeO4trvDiHtZzD+oKCZDlMLz2ohwR91QhorhrrRdiCHhH+6u01p8APbOkd5z85NIJPH7j6QDSBljodfzo3+uZ/LN3ArZZxT3TYUMRWgrZ0u4Oe064MkoNIcvPeb15ydxThz7luYPRNnTW+DIyHTZeW3tIrBmhV/H3Zfs43hSYZ7UHiXvYzD3o78BbLfPh1uqAhTAgvC3jLS/uL5l7ytCj4q6UmqOUWqGUWlFdnbzJRA67jW/NqmDBtmpeXnkg8gmCkMZYl8ozBlRDG4e1tHXsuV/9+JKAfcFdIQHa2o3ji3JlQDVV6FFx11o/obWeqrWeWlra/at/d8Y3ZowmP8vBliPSBlhIH6Jd2NpKcLWMzabQWgcMqjYHZ+6d3MfjIaRcxpu5i+eeOvQ5W8aLUoqKsjyW7qpl0Y6jyQ5HEKKitb3j2dVWsbY+Dq2WMUohrRUyIbZMhA8RFaTu3mv1F889ZYimFPIFYAkwTil1QCl1i1LqNqXUbeb+gUqpA8B3gP9nHlPQvWEnhjFleeyoauD6p5ax8dCJZIcjCBEJzrCtnGj2e+1WcXYH17ljzFBts1TCxCLuwV0hAS6bNBiAwmyxZVKFiC1/tdbXRdh/BAhdvDAN6J/rXzD3ofe3c8NZIzhzVLG0GhVSFqu4ezw6oLNiVX2r73GbW2NWJ3Y4icnV3knm3skU1uD2AwD3XTaR71w4VtoPpBB9WsU+c7LRw/qUIYW8vbGSG/+yXAZYhZSm2TI7Nbg1QGVdi++x1XIJN4kJdEADvY4GVL1YbR6P1iG2jMNuozgvEyF16NPiPmlYP/b85rN89tRBvm1r90tTMSF1sWbYbUETjKoDMvfw4p7pNCcxeSJk7kHibvX6jVLILv4HhB6jT4u7lzGleb7H6w+K9y6kLlZbpi1ocLXRmtV3IO5Om8KmjOy7NQZxt/azMWwZUfdUR8QdqBjgF/dtlfUysUlIWZo7EHCA1gDh94uz1XO32RQZDhtNLnfA+c0RbJnGVn+LYcnc0wMRd2BoUY7vcbtHs2RXTRKjEYSOsWbuwc2+rJl4oOfuf2xTRpXYtsr6mGyZxoD+8aGTmITUQ8QdsNsU8+acxcK7ZlKU4+SFZfvCLgwsCMmmM8/dKu6Btoz/GLtNMX5gAbuONtJgycZDesvo4MzdUqUjmXtaIOJuclZ5McOLc7h66jDe2VTJD/61PtkhCUIIndoyFoFud1vr3P3HKaUYPygft0ez6ZB/dnaL1VPXOoItE1otI6QeIu5B3HXxOM6pKOGN9Yd5cuEu6lvSotml0EcIsGXagz338LaM1XO3K8VJg4w5hussxQPHLM3Gws1f+tUbm6kz/xbCdYUUUg8R9yAcdhuXTRpMk8vNL9/YzJMLdyU7JEHwEVAt00nm3lG1jN2mGNIvG4B9tcZSk9lOO1X1/hp5b5vf66YN45dXngzAliP1/OWj3UD4rpBC6iHiHobTRxT5Hi/YVs23563m+WX7khiRIBi0uDrx3Ns68tyta6gqspx2cjPsHDnRDMCQouyA2a1eF2d4/1wumjAw4FyIvLi2kBqIuIdhVEku00b1B2DtgRO8suYQTyzcmeSoBAFaLaJ99eNLAnoidTygas3cjZ/FeZlU1hmCPrQom+o6v7h7B1MdNkVepr9DyfFml/FABlTTAhH3MCilePHW6dx18TgAyktz2X+sWerfhaRjrV8HWLvfKu5unxfu6qjO3VRla/fGIf2yqW9tZ1ulsTKZd2k9m02R5fRLhLe9gbZcR0hdRNw74ZazRzFvzlncffE43B7Niyv2o7Xm129s5uIHF/Lh1qpkhyj0MYKXvauzDPi3tnt8mXaHtoyp/iV5fnH3zvO46MGF3PXS2oDMXSnF+989jynD+3HkhCnuYdZQFVIPEfdOyHLaOau8mJOHFALwk1c38vdl+3jio11sraznofe3A3DN40t4bIHYNkL3EzyIWmdp89va5iE/yxlyXKDnbvy0Zu5Di7J9j19aeYBDxw0v3vtBMLo0j1HFuT4bJ1xXSCH1EHGPgiH9srn+zOEA3P/WFrSGr3xqJKv2Hee/6w6xbHctv3lzC88t3RtSniYIiSR4ELW+xV9/3truDpu5B5dCQmC760GFWQHX/NhcvMZuUfABhVlU1rXg8WijK6Soe8oj4h4FSil+eeUpTBrWj7qWdqaXF3Pzp0cB8NPXNvmO+/ErG3jqYymdFLqPNrcHh6XIPMSWyTLE3dXBJKZwtsyEwQVcOGEAr3/rbAqznXy03Vjf2HqfQYVZtHs01Q2tRilkgv9fQuIRcY+BKcP6AXD1GUMZ1j+b/CwHRxtaA46Zt3w/VZa+2oKQSNrdmpwM/4IYAbZMu4d8U9ytHSPbPZoBBZmUl+ZyzRnDAMjJMI4rynGSk+HgyZumMnFwIZOH9fMN0loXAhlTZjTX23KkXrpCpgki7jFw2eTBnD++jNkTB6GUojTf+Gp73lj/Yt9V9S18a97qZIUo9HJcbo9PmAHqLLZMS5ub3DC2jEdrhhXl8MF3ZzCo0PDXTx1qjCP96brTAq4/vH+Or+eMNXOfOMg4ftOhOimFTBMiLrMn+DlteBFPf+UM3/Mscx2zOeeWs2BbNd+fPZ6q+hb+8cn+kCXQBCERtLkdVgJaAAAcLUlEQVQ95GT6M/f6IFsmP5zn7tbYg96LJw8pZOevLgnZbh1czbQsN1mY42RIv2w2Ha4zV2ISUh3J3OPgwWsm8/UZo5leXsyG+y7mtvPKqSjLp8nl5h8r9ktdvJBw2t2aXGvm3mwZULVk7oGee6i4A2G3WdtfVwzID9g3YXABmw6dkGqZNEHEPQ7GDczn+7PHYzNn8imlfAt/3POv9dKXRoiKljY3J5qja1DncnvItnruQZl7ltOG065CqmXCCXk4rJl7eUluwL4Jg4xWwW6PlklMaYCIe4KpKPOv6vSv1Qepa2kL+AMUUpPaRher9x1Lyr2/+NgSJt33TlTHtrs9AXZJk8tNu9tj/PNoMh12nHZbwHoEHq0D/PPOGNbfn7kH24oTBhfgbSsj0p76RBR3pdTTSqkqpdSGDvYrpdRDSqkdSql1SqnTwh3XV+iXk0Gmw4bDpth9tJFTf/oO590/P9lhCRGYu3gPNzy1jA+3VnHgWFOP3juWdXvb3KFCXdvo8rX4zXTYcNptAfXwhuceXR5XlGNMgvr0mOKQfRPMVsGA+DJpQDS/8bnA7E72fwaoMP/NAR6NP6z0Zu29F7Hsh7N8X4WPNbVJX/gUp76ljUaXmzteWM3cRXuiOsfj0dz3n41sPVLfvcFZaHN7cJrdv5x24/01+48f+TpCGuKumLt4j79XjEf7GoZFQinF8h/O4i9fPiNk39CibF+ppUh76hPxV661XgjUdnLI5cCz2mAp0E8pNShRAaYjWU47xXmZTBvZ37dt+e5ajja0snb/8SRGJnSEd2ZxfUs7TVEOhO+uaeSvi/ZwZ4JKX4NbC3R0jNNuY89vPsvqn1xESV4GtY0uX5/3TKedow1G98Zv/H2VcY7HgyNadQfKCrLIctpDtiulfNm7JO6pTyI89yHAfsvzA+a2Ps+cc8u5YvJgMh023t1UyQW/X8DljyzCE26pGyGpWNtGRNtC4qjZAz2cEHaFJlfkD5V2j/Zl7HmZDm47bzQANaagW/14b/uAuuZ2CsyeM/EyYbAh7jKgmvr0aJ27UmoOhnXD8OHDe/LWSWHm+DJmji8j+1/reWG5f7GPxxbu5OPtR/npZRMZG1RuJiQH67J00Yr7IXOxC69PHS/NLjeF2Z1fq63db8sAFJjHe1dSynT4P2jKCjLRWnOi2UW/BMXoy9wTcjWhO0lE5n4QGGZ5PtTcFoLW+gmt9VSt9dTS0tJwh/RKbjuvnAzLH+T9b21l8c4afvafTWhZ1SYlaOuCuB885hX3jAhHRkeTqz3iMS63DrBYvB8GG83FrgdamoA1tLbT5HLT5tYRPzSixZu5S+Ke+iRC3F8DbjKrZs4CTmitDyfgur2GEcW5rPrJhbzyzU/7tl1yykA+3nGU3UcbkxiZ4MUq6Na1SDvj4HEjW45n2Tnrh/uu6kaueXyJb1GMcLR7PGTY/crqtVtW7jXKOMeU5fGHayaTm2GnttHlq5/vlyBxryjLZ1j/bIYX50Y+WEgq0ZRCvgAsAcYppQ4opW5RSt2mlLrNPOQNYBewA3gS+Ea3RZvG5GU6mGw2HgO44/wKwP9HKSQX6xJ1rigGNgEOmn3Po/HKO8K64PWD721j2e5a/rUq7BdfwLBlwmXuq/YeozQ/k8JsJ1dMGcLVZwyjtsHF8SZT3BNky2Q4bHx09/lcNmlwQq4ndB8RPXet9XUR9mvgmwmLqJdz67nl2G2KcQPyyc9y8NdFe5g2qj8jJBNKKl0ZUD1sintzHG0mvE26wMjcAV+5YTjaPDrIczeOrW9t5xSzGRhAcW4G9a3tPi++MDsx1pGQPsgM1R7mnktO4m6zZcGYsjw2Ha7j9ueli2Sy6cqAqleY48ncGyxdHb0fEp21IjBKIf22jNVLH2OZHe1djMNr+yUqcxfSBxH3JPL92eMBY4ZitD6v0D0Eeu7RibtX1OMR98bW0HO9ZY3BuD0arQnI3L0rLwGMH+ifQVpsLsZx33+MxWQSNaAqpA8i7knkrPJiHrvB6Naw4WBdkqPp27i64Lk3m6LeHEWVS0fUt4Zm6YeON4ed0eyt6LGKu3XRDG8lC8CAgsCl8yRz73uIuCeZ00cYs1iX7qpJciR9m1hLIdvdHt+HQKJsGS9vbTzCKT8NbSTmF/fwdYjjB/rnTJw6pJCHvzTF9zw7QROthPRBxD3JlOZnMmV4P/67TqpHk0mstoy1RUFzPLZMUNY/otjflTF4DoS3GZizg1YC1pmyNpvi0lP9FS2yLF7fQ1ZiSgEumzSY+/6zif/9xxpONLcxcXABnz9tKKNKpIKmp7BaMdX1rdzzr/Xcd9lEMhzhhdQr6EU5Tupa2tFad0lAgzP3kcW57K0xulIea2qjf66/ysXbxtcRlLk/dN0UX6uBYJ648XR2yVyKPolk7inA5yYNJsNh49+rD/LBlir+9MEOnv54d7LDShqt7W7O/78Pmb+1qgfvGZitv7B8Hx9tr+7weK8VU5yXidujcbk9eDw65hnHdUHifqzJP5h6yCy19OIK47mDkRx89tTwvfoumjjQ139G6FuIuKcAJXmZXDk5sNdaex9uLnboeAu7jjZy76sbe+ye4Xz2zuwZb6uAYjOzbna5Kf/hG3z9b6tium9dc1tAsy9rJ9GDQeLut2XEYhEiI7ZMinD37HF8akwxl546mCseWcSRE82RT+qleC2PYPuhu9Bah62Q6WwNXG+MJXlGPbm35v2tjUdiunddSxsF2U5GleQytCibu2eP59JJxnvgcJC4t3eQuQtCOETcU4TivEwuN7P3gYVZ7K/t2dWAUgnvJJ6MHhIxb/14MN6p++Hw2zJG5v7rN7Z06d5GO14HL9463bdt0tBCMhw2Dp0I7DHTkS0jCOGQd0kKMqgwiy1H6nl3UyVgeNDvb65Ea90lXzfdONFs+M49JWId1bXXNoafTAR+ce9ndoR8fX3Xqp28mbsVpRSjinPZeChw+b12sWWEGJDMPQXxtm39n2dXMLgwy5fBPf8/Z3Lfa5s4u6KEH186IZkhdivejLmnbJmO6tprGl1sOHiCYUU5FAZNAmpuM2yYEZYFpTtjjbkCl7V5HBiee78wLYMvnDCAP3+4g6MNrT7rJ9wkJkHoCHmXpCD5llVzrF/NX155gK2V9Ty9aDc/fmUDX356eTLC63aOm7ZMj2XuHYj7wePNXPqnj7n9hdBBUm/mfnZFCf+5/eyAfS+u2M9lD3/MQ+9v92274pFFXPHIIupb2nhpxX7ft6+6lvaQzB3g0kmD8Gh4c4Pfw/cOqDqiXOxa6NvIuyQFmTqiKOD56h9fyMlDCnytYLOddp5bupcF26p9Xf+2Vdbzei+ZCOXN3L0CWN/SFnUzr67QUVXMwm1GKeS6AydC9nkHVLMz7AHdGAHufnkd6w6c4O/L9oac97P/bOKul9exap+Rydc1t1EQpgvkuAH5VJTl8Z+1h3zbvJl7hkNsGSEyIu4pyEmDCtj1q0t47IbT+cUVJ1OUm8H08mLf/t99cZLv8dr9J3hm8R4uenAh33x+VacVHumC13P3NtU65afvcNPTy7rtfpF6yQwqzArZ5s3cczqY1n/beaOprGvlRHNbwO/kiLkQR22jC611WM8dDN/90lMHs3x3LV975hM8Hk27x5zEJJm7EAXyLklRbDbF7JMHcsNZIwC4fWYFl08ezK3nlfOZUwax9t6LAMOXv/c1fz14uCzTyzsbj7DuwPGw+77/8jq+9UJqtB72Zu5NrnbcZr3/0l21Cbu+1prtlfW+5135VtDkcpNht/kWznjr2+dw+8wxvv3TRhnfvrZX1odMRgJD5FvaPLS5dYeLV19zxjAKs528t7mKLUfqfa9Lbqb0iREiI+KeJhTmOPnjtVO45zMnGc+zndjCfDv/ZE94EWx3e5jz3Eoue3hR2P2r9x/rUPh7Gm8p5NEGF4t3Hk349V9aeYALH1zI4h3GtdvCZO6l+ZlccFIZYLQjCKbZ1U52hl9kxw8s4MIJAwCwKWM5OoCnF+32tRMA/wzUA8eaqDM7P3oX3AhmYGEWb955DgBLdtWw6VAdmQ4bI2VhFyEKRNzTmPsuP5nbzhvN0KJs37bnl+1jy5HQ9sFbjvgz1SrTGvjpaxt5dY3h4x850UJlXWtKlFl6M9SG1nZu/It/0LjiR2+wtyb+PineDpz7jxmiGy5zH9Ivm6e+fAbfvqCCmkZXyAdAk8tNTkZgBu21V8YOyGdIv2zyMh28sf4Id1i+EW070gDAgWPN1JkfYh1l7gCD+2UzsjiHJTtr2HiojvGDCgKW2ROEjpB3SRpz41kj+MFnxnP/VacyojiHv371DFxuD1c+sphV+/xrs67ed4xL//Sx7/kHW6rweDRzF+/hznlraGxtp66lneY2N796YzNHG0IzVU8PtkOw9lex0ubW/HPlgbiv32R6+V7vOpy4eydQleYbZYjBC2gca3KFLIAxon8Ot88cw5M3TcVmU8ybcxbTRvUPWErP6+8fPNbM+1uM3jnlpZ1n4lOGF7Hx0Ak2HDrBREvPdkHoDKlz7wV8anQJC+6aCcDrd5zNlX9ezHdfXMv1Zw7H7dEs3mlkqt61Od/eeIQaywSdz/95se/xkx/tpjQ/kznn+ptN/fS1jTy/fB9bfz6721vHaq2paXBhtymf327loQ92cLy5jZ9dfnKX7+Fts+u1RVrD2DLebpBl+cZg6qIdR/loezVDirK56+LxHDjWzJB+2QHn2GyK7108zvf85CGFPHvzNJ5dsofdR5t4Yfk+3749NY08uXAX544tZeLgwGqbYEYW5/Lv1cY3rJMjHCsIXiRz72WUFWTxiytPZvfRRn7x+mZ+/eYWFmyr5sIJA/jvHWczbkA+87dW88DbW33nbLUMLgKs3nechtZ2zv/dh1z/1FLmLt6Dq93DxkOxrRbl9miW7qqJacCyrqUdl9vD8E4mBz27ZC/bK+u544XVNLbGvgpSvdmJ8Zhp/4SLb5y58IW3Uua7L63llTWHeGT+Tlra3Bw63syQouyQ84LJctqZc+5ovnvRWN+2SUMLOd7URk2jiy9NGx7xGiNL/K+FZO5CtIi490JmjC1l8rB+ZDlt3HH+GGwKvj5jNCOKc32i1Rmr9x3n0Q93sKu6kUU7/CtEedshNLnaqaxr6eh0H+9sPMK1Tyxl9h8XRu3l15iWUEle6KxNKxc+uJD/rD3UaVvejjhiTgw73uTC49G+AdPi3AzGDchn7lfP8K1vO3FwATd/elTA+eN//BZ1Le0hmXtnFFlmoX7tnHLAsH7OqSiJeK63r7/dpqL6/QkCRCnuSqnZSqmtSqkdSqkfhNk/Qin1vlJqnVLqQ6XU0MSHKkSLUoqHvzSFeXOm892LxrH557M5bbhRmpcXNGHmGzNCe30fqWvhb0v3MWNcKVlO/1tk/tYqXlqxnwt+t4Azf/W+TyS9NLa289iCnby98Qj7app8U+53VTdytMHFij21vs6GHXG0g8WhAcryM/nbLWcGbFuyM7blCecu2u2rNX92yV7OuX8+u482kuW0Max/Dk6HYsa4Mp8to5TiW7PGhL3W4BjE3W5T3DR9BL/9wil8btJgzhzVn5njS8nNjOyMjjCrYyrK8gJWWxKEzoj4zlJK2YFHgAuBA8AnSqnXtNabLIf9H/Cs1voZpdT5wK+BG7sjYCE6hhblMLTI+Dqf6fALwtVTh/HftYd9vcLvnj2eWSeV8cGWKh6ZvxOlQGujHHHKsCKONbpYe+AE08uLWbKrhrteXue71u/e2coDlglVcxfvCbB7rDz18S4eX7CLez4znluDFo9od3u45oml3HbeaJ/43zh9JKv3HefNO89h/7Embp67ggyHLSBzPXNUfz7YWsW3G10UmX3Vn1m8h345Tl+HTSv1LW38/PXNAdsOHm9me1UDI4tzyXTYUGHmgIXr/QJEZctYsY4TPHPztKjPK8x2MrgwiynD+0U+WBBMosncpwE7tNa7tNYuYB5wedAxE4APzMfzw+wXUoTRpXks+sH5nDe21Leg8ukj+nPXxeNZ9IPzWf3jC32VIicNyudP153GVz41kq+d47cmvnfRWC6eOIDFO2v8g5Ltbp5ZvIcBBZkB9/OWaT6+YBcQWIf/4dYqLnpwAct317Jy7zHe31zJUXOg96xR/dnxq0uoGJBPca5xzQyHjdL8TAYUZHLDWcP52jnlHDnRwndeXAMYzbnufW0jd85bE1Ddc/hEM194dDEvLN+H26N58dbpfGq0f8bvwm3VjC7N46rTh3L11GFRv5ZDY8jcg8ly2mPKwv9x63R+YM5xEIRoiKZaZgiw3/L8AHBm0DFrgc8DfwSuBPKVUsVa69i+Mws9RrjM0eshTxxSwOp9x5kwuIChRTn89LKJ1Jsi/tlTB3H7+RX85ePdvL2xklN/+g7P3TKNtzYcoaq+lb/dciY/eXWDb93OU4YUcuCYf4bme5ur+O+6Q8wcV8YvXt/MjqoGbjIboG2rrGdAgTGAaV071GuRlJgiv/SeWYBhmdx41kieXrSbqb94N8DSeXTBTs4qL2b57lrmfbKPvTVNrNx7jP65GZw+osg3UcpLeWkuX+xE2L85czSPLdjlq+B5/MbTKSsIbUvQXQyLsvukIHhJVCnk94CHlVJfARYCB4GQL7hKqTnAHIDhwyNXCQjJ4ZyKUqrqWgMGDPOznCy8ayYDCg2BtTY38040+vSYYs6uKOHXnz+F55fv49U1h2ht93DKkELWHzzBr648hR/+ez23P7+aEcU57K1pwqb8Swpuq2xgWP8cinKcARN1xg3I51uzKrhumiG+1nLM6aOLeXrRbo42uLj1vHKuPWM4Vz++pEN7aNb4Muw2FVLLP9WyvF047rp4PN+YMYaJ977N5GH9uHjiwIivoyAkk2jE/SBgTWmGmtt8aK0PYWTuKKXygC9orUPmsmutnwCeAJg6dWryp0IKYfnW+WO49dzykJr24cX+7HHC4ALOG1vKArNz4qfHFPPIl04D4MzyYvKznLy65hAnDy7gK2a1Sf/cDC6YUMaCrdXc9fI6Rpfmcv9Vk/jCo0adfUNrO6+uOeSbxu/FZlN858KxhGPaKEOUC7OdvtYM7/7vuby3uYrvvbQ25PiLTFEeXZpHZV0rv/n8KQzql815Y0sjvi65mQ6evXkaJw+RWnMh9VGRStSUUg5gGzALQ9Q/Ab6ktd5oOaYEqNVae5RSvwTcWuufdHbdqVOn6hUrVsQbv5Bkrn58Cct31/LfO84OEb31B04wflB+2L7sb64/zClDCxnSL5tR97xBToadJpeba88Yxs+vODmmXu7vbDzCSYMKQqyLkT94PeD5uAH5vPLNT5OdYedYo4stR+qZbvHeBSEdUEqt1FpPjXhcNPXHSqlLgD8AduBprfUvlVI/A1ZorV9TSl2FUSGjMWyZb2qtQ+ewWxBx7x0cONbEgm3VfGna8C7PXm1sbfdZJUP6ZSdsFuzH24+yu6aR/jkZnFne37eikSCkMwkV9+5AxF0QBCF2ohV3maEqCILQCxFxFwRB6IWIuAuCIPRCRNwFQRB6ISLugiAIvRARd0EQhF6IiLsgCEIvRMRdEAShF5K0SUxKqWpgbxdOLQGOJjicRCBxxU6qxiZxxUaqxgWpG1s8cY3QWkdshpQ0ce8qSqkV0czO6mkkrthJ1dgkrthI1bggdWPribjElhEEQeiFiLgLgiD0QtJR3J9IdgAdIHHFTqrGJnHFRqrGBakbW7fHlXaeuyAIghCZdMzcBUEQhAgkVdyVUrOVUluVUjuUUj8Isz9TKfUPc/8ypdRIy757zO1blVIXR3vN7o5NKXWhUmqlUmq9+fN8yzkfmtdcY/4r68G4Riqlmi33fsxyzulmvDuUUg+pLqyWEUdc11tiWqOU8iilJpv7euL1OlcptUop1W4uOmPd92Wl1Hbz35ct23vi9Qobl1JqslJqiVJqo1JqnVLqGsu+uUqp3ZbXa3KsccUTm7nPbbn/a5bto8zf+w7zfZARfN3uikspNTPoPdailLrC3Bf3axZFXN9RSm0yf1/vK6VGWPZ123sMrXVS/mGs6rQTKAcygLXAhKBjvgE8Zj6+FviH+XiCeXwmMMq8jj2aa/ZAbFOAwebjk4GDlnM+BKYm6TUbCWzo4LrLgbMABbwJfKan4go65hRgZw+/XiOBU4Fngass2/sDu8yfRebjoh58vTqKayxQYT4eDBwG+pnP51qP7enXzNzX0MF1XwSuNR8/Bny9J+MK+r3WAjmJeM2ijGum5X5fx/832W3vMa11UjP3acAOrfUurbULmAdcHnTM5cAz5uOXgVnmJ9jlwDytdavWejeww7xeNNfs1ti01qu1sWA4wEYgWymVqPXd4nnNwqKUGgQUaK2XauNd9SxwRZLius48N1FEjEtrvUdrvQ7wBJ17MfCu1rpWa30MeBeY3VOvV0dxaa23aa23m48PAVVA5NW9eyC2jjB/z+dj/N7BeB/02GsWxFXAm1rrphjvH09c8y33WwoMNR9353ssqeI+BNhveX7A3Bb2GK11O3ACKO7k3Giu2d2xWfkCsEoHrif7V/Pr34+78FUr3rhGKaVWK6UWKKXOsRx/IMI1uzsuL9cALwRt6+7XK9Zze+r1iohSahpGtrjTsvmX5tf/B7uYVMQbW5ZSaoVSaqnX+sD4PR83f+9duWYi4vJyLaHvsXhes1jjugUjE+/s3ES8x2RAtbtQSk0Efgvcatl8vdb6FOAc89+NPRjSYWC41noK8B3geaVUQQ/ev1OUUmcCTVrrDZbNyXy9Uhozu3sO+KrW2pup3gOMB87A+Kr//SSENkIbMy+/BPxBKTU6CTGExXzNTgHetmzusddMKXUDMBV4oLvuYSWZ4n4QGGZ5PtTcFvYYpZQDKARqOjk3mmt2d2wopYYC/wZu0lr7siqt9UHzZz3wPMZXuh6Jy7Swasz7r8TI9saaxw+1nN+V1yyu18skJKPqodcr1nN76vXqEPND+XXgR1rrpd7tWuvD2qAV+Cuxv15xx2b5ne3CGDOZgvF77mf+3mO+ZiLiMrka+LfWus0Sb7yvWVRxKaUuAH4EXGb5Jt+d77GkDqg6MAYQRuEfiJgYdMw3CRyEe9F8PJHAAdVdGAMbEa/ZA7H1M4//fJhrlpiPnRj+4209GFcpYDcfl5tvlv46/ODNJT0Vl/ncZsZT3tOvl+XYuYQOqO7GGOgqMh/32OvVSVwZwPvAt8McO8j8qYA/AL/pjvd+J7EVAZnm4xJgO+bgIvASgQOq3+ipuCzblwIzE/maRfnen4KRTFUEbe+295jWOnnibv4HLgG2mf/xH5nbfobx6QaQZb4pdpj/Wesf/4/M87ZiGUkOd82ejA34f0AjsMbyrwzIBVYC6zAGWv+IKbY9FNcXzPuuAVYBn7Nccyqwwbzmw5iT23rwdzkDWBp0vZ56vc7A8DQbMTLMjZZzbzbj3YFhf/Tk6xU2LuAGoC3o/TXZ3PcBsN6M7W9AXje99zuK7VPm/deaP2+xXLPc/L3vMN8HmT38uxyJkUDYgq4Z92sWRVzvAZWW39drPfEekxmqgiAIvRAZUBUEQeiFiLgLgiD0QkTcBUEQeiEi7oIgCL0QEXdBEIReiIi7IAhCL0TEXRAEoRci4i4IgtAL+f9QR1HBXDXhBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrfinder(0.001, 0.2, model_nn_copy, train_loader2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As taught in fastai class, learning rate is starting to increase after 0.05. We can choose 0.025 as good learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8758557327091694\n",
      "validation loss :  1.0232972564156522\n",
      "training loss for epoch  2 :  1.842201673425734\n",
      "validation loss :  1.02631219883555\n",
      "training loss for epoch  3 :  1.832166446528087\n",
      "validation loss :  1.028887576049136\n",
      "training loss for epoch  4 :  1.8295468958094716\n",
      "validation loss :  1.0362612998362668\n",
      "training loss for epoch  5 :  1.8241126706513264\n",
      "validation loss :  1.0324596455416728\n"
     ]
    }
   ],
   "source": [
    "train_epocs2(model_nn2, epochs=5, lr=0.025, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Training going down but validation up. let's add some regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8878458694865308\n",
      "validation loss :  1.0313210849909438\n",
      "training loss for epoch  2 :  1.8936595402968428\n",
      "validation loss :  1.028655474333419\n",
      "training loss for epoch  3 :  1.8919598865322769\n",
      "validation loss :  1.0280797334061456\n",
      "training loss for epoch  4 :  1.891211919952184\n",
      "validation loss :  1.0368618854542369\n",
      "training loss for epoch  5 :  1.8898136398444572\n",
      "validation loss :  1.0352515320187992\n"
     ]
    }
   ],
   "source": [
    "train_epocs2(model_nn2, epochs=5, lr=0.025,wd=1e-5, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch  1 :  1.8544896307090917\n",
      "validation loss :  1.0219936254098243\n",
      "training loss for epoch  2 :  1.8040295336395502\n",
      "validation loss :  1.0173002376998823\n",
      "training loss for epoch  3 :  1.770378882996738\n",
      "validation loss :  1.0184230355872321\n",
      "training loss for epoch  4 :  1.7562920916825533\n",
      "validation loss :  1.0282377926344723\n",
      "training loss for epoch  5 :  1.7439961267324784\n",
      "validation loss :  1.0265097120373519\n"
     ]
    }
   ],
   "source": [
    "train_epocs2(model_nn2, epochs=5, lr=0.001,wd=1e-6, unsqueeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat = model_nn2(Variable(torch.LongTensor(df_val.cust_Id.values)).cuda(),\n",
    "#               Variable(torch.LongTensor(df_val.movie_Id.values)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat.data.cpu().numpy().min(), y_hat.data.cpu().numpy().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
